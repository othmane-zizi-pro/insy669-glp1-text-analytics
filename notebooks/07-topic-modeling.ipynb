{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07 - Topic Modeling & Clustering\n",
    "## INSY 669 Text Analytics | GLP-1 Weight Loss Drugs\n",
    "\n",
    "This notebook discovers latent themes in each corpus using:\n",
    "1. **LDA (Latent Dirichlet Allocation)** - probabilistic topic modeling\n",
    "2. **K-Means Clustering** - unsupervised document grouping\n",
    "3. **Topic comparison** - how topics differ between public and media corpora"
   ],
   "id": "88274c90"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ],
   "id": "74d87d83"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Load Data"
   ],
   "id": "eca73967"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_public = pd.read_csv('../data/public_processed.csv')\n",
    "df_media = pd.read_csv('../data/media_processed.csv')\n",
    "df_public = df_public.dropna(subset=['clean'])\n",
    "df_media = df_media.dropna(subset=['clean'])\n",
    "print(f\"Public: {len(df_public)} | Media: {len(df_media)}\")"
   ],
   "id": "8ca3ef82"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 LDA Topic Modeling\n",
    "\n",
    "LDA assumes each document is a **mixture of topics** and each topic is a **distribution over words**.\n",
    "Unlike K-Means (hard assignment), LDA provides soft, probabilistic topic membership."
   ],
   "id": "5d13e75a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lda(texts, n_topics=5, max_features=3000, n_top_words=10):\n",
    "    \"\"\"Fit LDA and return model, vectorizer, and topic-word matrix.\"\"\"\n",
    "    cv = CountVectorizer(max_features=max_features, min_df=5, max_df=0.9)\n",
    "    dtm = cv.fit_transform(texts)\n",
    "    \n",
    "    lda = LatentDirichletAllocation(\n",
    "        n_components=n_topics,\n",
    "        random_state=42,\n",
    "        max_iter=20,\n",
    "        learning_method='online'\n",
    "    )\n",
    "    lda.fit(dtm)\n",
    "    \n",
    "    feature_names = cv.get_feature_names_out()\n",
    "    topics = []\n",
    "    for topic_idx, topic in enumerate(lda.components_):\n",
    "        top_words = [feature_names[i] for i in topic.argsort()[:-n_top_words-1:-1]]\n",
    "        topics.append(top_words)\n",
    "        print(f\"  Topic {topic_idx + 1}: {', '.join(top_words)}\")\n",
    "    \n",
    "    return lda, cv, dtm, topics"
   ],
   "id": "ab0f94cc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PUBLIC CORPUS - LDA Topics\")\n",
    "print(\"-\" * 50)\n",
    "lda_pub, cv_pub, dtm_pub, topics_pub = fit_lda(df_public['clean'], n_topics=5)"
   ],
   "id": "a96858aa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MEDIA CORPUS - LDA Topics\")\n",
    "print(\"-\" * 50)\n",
    "lda_med, cv_med, dtm_med, topics_med = fit_lda(df_media['clean'], n_topics=5)"
   ],
   "id": "83ad0e9b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Choosing Number of Topics\n",
    "\n",
    "We evaluate different values of k using **perplexity** (lower is better) and **log-likelihood** (higher is better)."
   ],
   "id": "f21d92b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = range(2, 12)\n",
    "\n",
    "cv_all = CountVectorizer(max_features=3000, min_df=5, max_df=0.9)\n",
    "dtm_all_pub = cv_all.fit_transform(df_public['clean'])\n",
    "\n",
    "perplexities = []\n",
    "log_likelihoods = []\n",
    "\n",
    "for k in k_range:\n",
    "    lda_k = LatentDirichletAllocation(\n",
    "        n_components=k, random_state=42, max_iter=20, learning_method='online'\n",
    "    )\n",
    "    lda_k.fit(dtm_all_pub)\n",
    "    perplexities.append(lda_k.perplexity(dtm_all_pub))\n",
    "    log_likelihoods.append(lda_k.score(dtm_all_pub))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(k_range, perplexities, 'o-', color='#E94560', linewidth=2)\n",
    "axes[0].set_xlabel('Number of Topics (k)')\n",
    "axes[0].set_ylabel('Perplexity')\n",
    "axes[0].set_title('LDA Perplexity vs Number of Topics', fontweight='bold')\n",
    "\n",
    "axes[1].plot(k_range, log_likelihoods, 's-', color='#2196F3', linewidth=2)\n",
    "axes[1].set_xlabel('Number of Topics (k)')\n",
    "axes[1].set_ylabel('Log-Likelihood')\n",
    "axes[1].set_title('LDA Log-Likelihood vs Number of Topics', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/lda_topic_selection.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "a2e744e8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 Topic Distribution per Document"
   ],
   "id": "e15ed07b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get document-topic distributions\n",
    "doc_topics_pub = lda_pub.transform(dtm_pub)\n",
    "doc_topics_med = lda_med.transform(dtm_med)\n",
    "\n",
    "# Average topic proportions per corpus\n",
    "avg_pub = doc_topics_pub.mean(axis=0)\n",
    "avg_med = doc_topics_med.mean(axis=0)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].bar(range(1, len(avg_pub) + 1), avg_pub, color='#2196F3', alpha=0.8)\n",
    "axes[0].set_xlabel('Topic')\n",
    "axes[0].set_ylabel('Average Proportion')\n",
    "axes[0].set_title('Public: Average Topic Distribution', fontweight='bold')\n",
    "axes[0].set_xticks(range(1, len(avg_pub) + 1))\n",
    "\n",
    "axes[1].bar(range(1, len(avg_med) + 1), avg_med, color='#FF9800', alpha=0.8)\n",
    "axes[1].set_xlabel('Topic')\n",
    "axes[1].set_ylabel('Average Proportion')\n",
    "axes[1].set_title('Media: Average Topic Distribution', fontweight='bold')\n",
    "axes[1].set_xticks(range(1, len(avg_med) + 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/topic_distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "7798a400"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 K-Means Text Clustering\n",
    "\n",
    "K-Means provides **hard assignment** of documents to clusters. We cluster the combined corpus\n",
    "and see if clusters naturally separate public from media documents."
   ],
   "id": "4fe065b5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine corpora for clustering\n",
    "all_clean = pd.concat([df_public['clean'], df_media['clean']], ignore_index=True)\n",
    "all_labels = ['Public'] * len(df_public) + ['Media'] * len(df_media)\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=3000, min_df=5, max_df=0.9)\n",
    "X_tfidf = tfidf.fit_transform(all_clean)"
   ],
   "id": "4a7f4b29"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow method and silhouette scores\n",
    "k_range = range(2, 11)\n",
    "inertias = []\n",
    "silhouettes = []\n",
    "\n",
    "for k in k_range:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    km.fit(X_tfidf)\n",
    "    inertias.append(km.inertia_)\n",
    "    silhouettes.append(silhouette_score(X_tfidf, km.labels_, sample_size=500, random_state=42))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(k_range, inertias, 'o-', color='#E94560', linewidth=2)\n",
    "axes[0].set_xlabel('Number of Clusters (k)')\n",
    "axes[0].set_ylabel('Inertia (WCSS)')\n",
    "axes[0].set_title('Elbow Method', fontweight='bold')\n",
    "\n",
    "axes[1].plot(k_range, silhouettes, 's-', color='#2196F3', linewidth=2)\n",
    "axes[1].set_xlabel('Number of Clusters (k)')\n",
    "axes[1].set_ylabel('Silhouette Score')\n",
    "axes[1].set_title('Silhouette Score vs k', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/kmeans_selection.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "best_k = k_range[np.argmax(silhouettes)]\n",
    "print(f\"Best k by silhouette: {best_k} (score: {max(silhouettes):.4f})\")"
   ],
   "id": "e82ec7ba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit K-Means with k=2 (natural media vs public split)\n",
    "km2 = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "km2.fit(X_tfidf)\n",
    "\n",
    "# Cross-tabulation: do clusters align with media vs public?\n",
    "ct = pd.crosstab(\n",
    "    pd.Series(all_labels, name='True Label'),\n",
    "    pd.Series(km2.labels_, name='Cluster')\n",
    ")\n",
    "print(\"K-Means (k=2) vs True Labels:\")\n",
    "print(ct)\n",
    "\n",
    "# Purity\n",
    "purity = sum(ct.max(axis=1)) / ct.values.sum()\n",
    "print(f\"\\nCluster purity: {purity:.4f}\")"
   ],
   "id": "1f422f64"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top terms per cluster\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "order_centroids = km2.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "for i in range(2):\n",
    "    top_terms = [feature_names[ind] for ind in order_centroids[i, :15]]\n",
    "    print(f\"Cluster {i}: {', '.join(top_terms)}\")"
   ],
   "id": "b31427cd"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6 Summary"
   ],
   "id": "dc2f2240"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TOPIC MODELING & CLUSTERING SUMMARY\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"\\nLDA Topics discovered:\")\n",
    "print(f\"  Public corpus: 5 topics\")\n",
    "print(f\"  Media corpus:  5 topics\")\n",
    "print(f\"\\nK-Means Clustering:\")\n",
    "print(f\"  Best k by silhouette: {best_k}\")\n",
    "print(f\"  k=2 cluster purity: {purity:.4f}\")\n",
    "print(f\"\\nKey insight: {'Clusters naturally separate media from public text' if purity > 0.7 else 'Some overlap between media and public language'}\")"
   ],
   "id": "6ab6e2d7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}